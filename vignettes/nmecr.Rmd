---
title: "Introduction to nmecr"
author: 
  - Mrinalini Sharma^[msharma@kw-engineering.com]
  - David Jump^[djump@kw-engineering.com]
  - Devan Johnson^[johnson@kw-engineering.com]

date: "November 22, 2019"
output: pdf_document
vignette: >
  %\VignetteIndexEntry{Introduction to nmecr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

devtools::load_all()
library(dplyr)
library(lubridate)
library(ggplot2)
library(tidyr)
```

The `nmecr` package was written to integrate the past efforts of the energy efficiency industry to streamline meter-based Measurement & Verification of EE projects. It brings together simple linear regression with outside air temperature , the change point models (from ASHARE 1040-RP), and the Time-of-Week and Temperature model (developed by the Lawrence Berkeley National Laboratory) and builds enhancements upon these by accurately predicting the energy use profiles of facilities with multiple operating modes.  

#### Normalized Metered Energy Consumption (NMEC)

Meter-based energy efficiency programs are proliferating across the globe. This proliferation is influenced by the widespread availability of high frequency energy use measurements from new metering technology as well as advancements in statistical regression and other empirical energy data modeling methodologies. Program administrators may report savings as the overall reduction in normalized metered energy consumption (NMEC). This method to determine savings is based on analysis of meter data collected prior to and after energy efficiency and conservation measures have been installed. Referred to as advanced measurement and verification (M&V) by the industry, this time-granular data and updated modeling methods provide several advantages over other methods used to quantify the benefits of energy efficiency:

* It reliably determines the actual savings achieved at the meter

*	It provides fast feedback on the facility's energy performance and savings progress

*	It enables identification and troubleshooting of issues that prevent savings realization
 
The `nmecr` package streamlines the application of the NMEC approach by enabling the:

* Management of high frequency, high volume data.

* Execution of advanced, state-of-the-art time-series data modeling algorithms.

* Comprehensive assessment of the validity of energy data models in specific applications.

* Quantification of uncertainties and risks associated with the energy savings projections in accordance with ASHRAE Guideline 14.

## Data

`nmecr` includes two datasets: `temp` and `eload`. These contain three years (03/01/2012 - 02/28/2015) of outside air temperature data and energy use data from a commercial building in North America. Energy conservation measures were installed between 03/01/2013 and 02/28/2014 in this building and so, we will use the first year (03/01/2012 - 02/01/2013) as the pre-implementation dataset and the third year (03/01/2014 - 02/28/2015) as the post-implementation dataset. 

```{r, results='markup'}
# Load data into an R session:

data(eload)
data(temp)

```

`eload` and `temp` are data frames with the two variables each. When using `nmecr` functions, ensure that the column headers of your datasets are the same as those shown below.

Eload:

```{r eload, results='markup', echo=FALSE}
head(eload, n=5)
```

Temp:

```{r temp, results='markup', echo=FALSE}
head(temp, n=5)
```

## Baseline and Performance Period Dataframes for Modeling

`create_dataframe()` combines the `eload` and `temp` dataframes into one, filters by the specified start and end dates, and aggregates to an hourly, daily, or a monthly data interval. If an operating mode dataframe is supplied, `create_dataframe` creates a list with two objects: dataframe, operating_mode_data.

```{r baseline_df, results='markup'}

# Baseline Dataframe

baseline_df <- create_dataframe(eload_data = eload, temp_data = temp, 
                                start_date = "03/01/2012 00:00", 
                                end_date = "02/28/2013 23:59", 
                                convert_to_data_interval = "Daily")

head(baseline_df$dataframe, 5)

```

```{r performance_df, results='markup'}

# Performance Period Dataframe

performance_df <- create_dataframe(eload_data = eload, temp_data = temp, 
                                   start_date = "03/01/2014 00:00", 
                                   end_date = "02/28/2015 23:59", 
                                   convert_to_data_interval = "Daily")

head(performance_df$dataframe, 5)

```

## Energy Data Modeling

The baseline and performance period dataframes can then be used for energy data modeling using one of the four modeling algorithms available in nmecr:

* `model_with_TOWT()*`: Time-of-Week & Temperature and Time-Only algorithms

* `model_with_CP()`: 3-Parameter Heating, 3-Parameter Cooling, 4-Parameter, and 5-Parameter algorithms

* `model_with_SLR()`: Simple Linear Regression algorithm

* `model_with_HDD_CDD()`: Heating Degree Day only, Cooling Degree Day only, and a combination of Heating Degree Day and Cooling Degree Day algorithms

The common arguments for these four algorithms are:

1. training_list (output from `create_dataframe()`)
1. model_input_options (see below)

`*model_with_TOWT()` has an additional argument (prediction_list) for creating data models and predictions together. 

### model_input_options()

The four modeling algorithms have many specifications in common that can be specified using the `assign_model_inputs()` function. The following code chunk shows the default values for these model inputs

```{r model inputs, results='markup'}

model_input_options <- assign_model_inputs(timescale_days = NULL, interval_minutes = 15, 
                                           has_temp_knots_defined = FALSE, 
                                           equal_temp_segment_points = TRUE,
                                           temp_segments_numeric = 6, 
                                           temp_knots_value = c(40, 45, 50, 60, 65, 70), 
                                           initial_breakpoints = c(50,65), 
                                           regression_type = "TOWT")

```

Before creating data models, it is a good practice to visualize the energy use profiles:

#### Baseline Energy Use

```{r baseline profile, results='markup', echo=FALSE, fig.height = 3, fig.width = 7}

ggplot2::ggplot(baseline_df$dataframe, aes(x = time, y = eload)) +
  geom_line() +
  xlab("Time") +
  scale_y_continuous(name = "Energy Consumption (kWh)", labels = scales::comma)+
  theme_minimal()

```

```{r baseline scatter, results='markup', echo=FALSE, fig.height = 3, fig.width = 7}

ggplot2::ggplot(baseline_df$dataframe, aes(x = temp, y = eload)) +
  geom_point() +
  xlab("Temperature") +
  scale_y_continuous(name = "Energy Consumption (kWh)", labels = scales::comma)+
  theme_minimal()

```

Due to the high dependence on temperature, we can begin the data modeling using Simple Linear Regression and compare that to other modeling algorithms

### Model Creation

Simple Linear Regression:

```{r SLR_model, results = 'markup'}

SLR_model <- model_with_SLR(training_list = baseline_df, 
                            model_input_options = 
                              assign_model_inputs(regression_type = "SLR"))

```


```{r SLR model, fig.width=7, fig.height=3, echo = FALSE, results='hide'}

SLR_df <- SLR_model$training_data %>%
  tidyr::gather(key = "variable", value = "value", -c("time", "temp", "CDD", "HDD"))

ggplot2::ggplot(SLR_df, aes(x = time, y = value)) +
  geom_line(aes(color = variable), size = 1) +
  xlab("Time") +
  scale_y_continuous(name = "Energy Consumption and Model Fit", labels = scales::comma) +
  theme_minimal()
  
```

``` {r SLR scatter, fig.width=7, fig.height=3, echo = FALSE, results='hide'}
  
 ggplot2::ggplot(SLR_df, aes(x = temp, y = value)) +
  geom_point(aes(color = variable), size = 1) +
  xlab("Temperature") +
  scale_y_continuous(name = "Energy Consumption and Model Fit", labels = scales::comma) +
  theme_minimal() 


```

Three Parameter Heating:

```{r 3PH_model, results='markup'}

Three_PH_model <- model_with_CP(training_list = baseline_df, 
                                model_input_options = 
                                  assign_model_inputs(regression_type = 
                                                        "Three Parameter Heating"))

```

```{r 3PH model, fig.width=7, fig.height=3, echo = FALSE, results='hide'}

Three_PH_df <- Three_PH_model$training_data %>%
  tidyr::gather(key = "variable", value = "value", -c("time", "temp", "CDD", "HDD"))

ggplot2::ggplot(Three_PH_df, aes(x = time, y = value)) +
  geom_line(aes(color = variable), size = 1) +
  xlab("Time") +
  scale_y_continuous(name = "Energy Consumption and Model Fit", labels = scales::comma) +
  theme_minimal()
```

```{r 3PH scatter, fig.width=7, fig.height=3, echo = FALSE, results='hide'}
 ggplot2::ggplot(Three_PH_df, aes(x = temp, y = value)) +
  geom_point(aes(color = variable), size = 1) +
  xlab("Temperature") +
  scale_y_continuous(name = "Energy Consumption and Model Fit", labels = scales::comma) +
  theme_minimal() 

```

Time of Week and Temperature:

```{r TOWT_model, results='markup'}

TOWT_model <- model_with_TOWT(training_list = baseline_df, 
                              model_input_options = 
                                assign_model_inputs(regression_type = "TOWT"))

```

```{r TOWT model, fig.width=7, fig.height=3, echo = FALSE, results='hide'}

TOWT_df <- TOWT_model$training_data %>%
  tidyr::gather(key = "variable", value = "value", -c("time", "temp", "CDD", "HDD"))

ggplot2::ggplot(TOWT_df, aes(x = time, y = value)) +
  geom_line(aes(color = variable), size = 1) +
  xlab("Time") +
  scale_y_continuous(name = "Energy Consumption and Model Fit", labels = scales::comma) +
  theme_minimal()
```

```{r TOWT scatter, fig.width=7, fig.height=3, echo = FALSE, results='hide'}
 ggplot2::ggplot(TOWT_df, aes(x = temp, y = value)) +
  geom_point(aes(color = variable), size = 1) +
  xlab("Temperature") +
  scale_y_continuous(name = "Energy Consumption and Model Fit", labels = scales::comma) +
  theme_minimal() 

```

The plots show that the Time-of-Week and Temperature algorithm models the energy use profile better than the other two. 

This insight can be confirmed through model statistics by using the `calculate_summary_statistics()` function. The following table summarizes the results from this function for each of the models assessed above:

```{r stats, results='markup', echo=FALSE}

SLR_stats <- calculate_summary_statistics(SLR_model)

Three_PH_stats <- calculate_summary_statistics(Three_PH_model)

TOWT_stats <- calculate_summary_statistics(TOWT_model)

all_stats <- bind_rows(SLR_stats, Three_PH_stats, TOWT_stats)

model_names <- c("SLR", "Three_Parameter_Heating", "TOWT")

all_stats <- bind_cols("Model Name" = model_names, all_stats)

all_stats

```


## Energy Load Prediction

The energy use models can be used to predict energy use during a different time period. This functionality is central to calculating the Adjusted Baseline Energy Use, which can be further utilized to calculate Avoided Energy Use (or Energy Savings)

```{r model predictions, results='markup'}

TOWT_predictions <- calculate_model_predictions(training_list = baseline_df, 
                                                prediction_list = performance_df, 
                                                modeled_object = TOWT_model)

```

```{r TOWT pred, fig.width=7, fig.height=3, echo = FALSE, results='hide'}

TOWT_df <- TOWT_predictions$predictions %>%
  tidyr::gather(key = "variable", value = "value", -c("time", "temp", "CDD", "HDD"))

ggplot2::ggplot(TOWT_df, aes(x = time, y = value)) +
  geom_line(aes(color = variable), size = 1) +
  xlab("Time") +
  scale_y_continuous(name = "Energy Consumption and Predictions", labels = scales::comma) +
  theme_minimal()
```

```{r TOWT pred scatter, fig.width=7, fig.height=3, echo = FALSE, results='hide'}
 ggplot2::ggplot(TOWT_df, aes(x = temp, y = value)) +
  geom_point(aes(color = variable), size = 1) +
  xlab("Temperature") +
  scale_y_continuous(name = "Energy Consumption and Predictions", labels = scales::comma) +
  theme_minimal() 

```

The California Public Utilities Commission requires savings to be detectable above model variations. `nmecr` interprets this using ASHRAE Guideline 14 - 2014's formulation for savings uncertainty, which relates the savings uncertainty to the model goodness of fit metric CV(RMSE), the confidence level, the amount of savings, the amount of data used to develop the model, and the amount of data required to report savings. It includes a correction when autocorrelation is present (which occurs mainly in models developed from daily and hourly data). LBNL has shown this uncertainty formulation with correction for autocorrelation underestimates the savings uncertainty. More work on this issue is needed. Until a better formulation is available, `nmecr` uses ASHRAE's method only as an estimation. 

```{r savings summary, results='markup'}

TOWT_savings <- calculate_savings_and_uncertainty(prediction_results_list = 
                                                    TOWT_predictions, 
                                                  modeled_object = TOWT_model, 
                                                  model_summary_statistics = TOWT_stats,
                                                  confidence_level = 90)

TOWT_savings$savings_summary_df
```

Savings achieved at the meter for this project amount to ~7% of the Adjusted Baseline Use with an associated savings uncertainty of 15%. ASHRAE requires that the savings uncertainty for a project be below 50% at the 90% confidence level. The 15% uncertainty is well below this threshold. 

The savings percentage required to meet the threshold of 50% uncertainty is 2.1% (as shown by the output above, see: savings_pct_for_50pct_uncertainty).

